# Attention-Deep-Learning
Implementing self attention, convolutional attention, multihead attention onto current architectures such as CNN, LSTM for Speech Audio Emotion Detection.

1️⃣ Dataset Link

- https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio

2️⃣ Final Presentation Link

- https://www.canva.com/design/DAFz7H_dNr0/jq5FBLKrBWTYf4b5BwsR4Q/edit

3️⃣ Models Experimented with and their accuracies:


- LSTM (~60%)
- CNN + LSTM (~80%)
- CNN + Bidirectional LSTM (86%)
- Attention methods used with CNN:
- CNN + Convolution Attention (72%) 
- CNN + Self Dot Product Attention (74%)
- CNN + Multihead Attention (74%)
- Ensemble Techniques (Majority voting) (88%)
- Attention methods used with Alexnet:
- Alexnet + Convolution Attention (65%)
- Alexnet + Self Dot Product Attention (65%)
- AlexNet (~77%)
